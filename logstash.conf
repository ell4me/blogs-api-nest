# обычный input, что бы слушать что отправляет filebeat
input {
  beats {
    port => 5044
  }
}

# фильтр в котором обрабатывается container.name = pg. Применяется grok-парсинг 2024-05-19 18:30:11 INFO: Starting PostgresSQL instance
# так как docker хранит логи в поле log,это нужно указать  "log" =>
# {"log":"2024-05-20 10:15:00 INFO: Server started\n","stream":"stdout","time":"2024-05-20T10:15:00.123456789Z"} - пример хранения
# date в конфигурацию Logstash, нужно чтобы значение из поля timestamp автоматически становилось @timestamp — это обеспечит правильную временную ось в Kibana
filter {
  if [container][name] =~ "pg" {
    grok {
      match => { "log" => "%{TIMESTAMP_ISO8601:timestamp} %{LOGLEVEL:level}:%{GREEDYDATA:log_message}" }
    }
    date {
      match => ["timestamp", "ISO8601"]
      target => "@timestamp"
      remove_field => ["timestamp"]
    }
  }
}

# output в elasticsearch
output {
  elasticsearch {
    hosts => ["http://elasticsearch:9200"]
    index => "logstash-%{+YYYY.MM.dd}"
  }
}
